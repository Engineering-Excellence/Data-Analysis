{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 로지스틱 회귀(Logistic Regression)\n",
    "공부시간, 과외시간과 시험성적 사이의 관계는 좌표로 나타냈을 때 형태가 직선으로 해결되는 선형 회귀를 사용하기에 적합했다.\n",
    "공부시간에 따른 점수가 아닌 합격 여부로 발표되는 시험이 있을 경우 직선으로 해결하기에 적합하지 못한 문제가 발생한다.\n",
    "이 때 사용하는 로지스틱 회귀는 참과 거짓 중에 하나를 내놓는 과정으로 참과 거짓을 구분한 시그모이드 형태('S'를 늘어뜨린 모양)의 선을 그어주는 작업이다.\n",
    "<br/>\n",
    "<img src=\"images/sigmoid.jpg\" alt=\"sigmoid\" width=\"1200\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공부시간: [2, 4, 6, 8, 10, 12, 14], 합격여부: [0, 0, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# 공부시간(x), 합격여부(y) → [공부시간, 합격여부]\n",
    "data = [[2, 0], [4, 0], [6, 0], [8, 1], [10, 1], [12, 1], [14, 1]]\n",
    "xData = [i[0] for i in data]    # 공부시간\n",
    "yData = [i[1] for i in data]    # 합격여부\n",
    "print(f'공부시간: {xData}, 합격여부: {yData}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [0.49131833],\n",
      "b = [0.59300641]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 10:41:34.615931: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n",
      "2023-02-02 10:41:34.621543: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# 가중치(w)와 편향(b)을 랜덤한 값으로 정한다.\n",
    "w = tf.Variable(tf.random_normal([1], dtype=tf.float64))  # 가중치\n",
    "b = tf.Variable(tf.random_normal([1], dtype=tf.float64))  # 편향\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(f'w = {sess.run(w)},\\nb = {sess.run(b)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 시그모이드 방정식(Sigmoid Equation)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e = 2.718281828459045\n"
     ]
    }
   ],
   "source": [
    "# np.e: numpy에서 자연로그(2.7182818...)를 의미하는 상수\n",
    "print('e =',np.e)\n",
    "Y = 1 / (1 + np.e ** -(w * xData + b))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "시그모이드 방정식의 오차를 계산하는 수식을 만든다.\n",
    "시그모이드 함수의 특성은 예측값(Y)이 항상 0 아니면 1이다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "loss = -tf.reduce_mean(\n",
    "    np.array(yData) * tf.log(Y) + (1 - np.array(yData)) * tf.log(1 - Y)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "오차를 최소로 하는 값을 찾는다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "gradient_descent = tf.train.GradientDescentOptimizer(0.1).minimize(loss)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "학습시킨다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =     0, loss = 2.449679\n",
      "epoch = 30000, loss = 0.015388\n",
      "epoch = 60000, loss = 0.008126\n",
      "epoch = 90000, loss = 0.005501\n",
      "epoch = 120000, loss = 0.004152\n",
      "epoch = 150000, loss = 0.003332\n",
      "epoch = 180000, loss = 0.002782\n",
      "epoch = 210000, loss = 0.002387\n",
      "epoch = 240000, loss = 0.002090\n",
      "epoch = 270000, loss = 0.001858\n",
      "epoch = 300000, loss = 0.001673\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(300001):\n",
    "    sess.run(gradient_descent)\n",
    "    if epoch % 30000 == 0:\n",
    "        print(f'epoch = {epoch:5d}, loss = {sess.run(loss):8.6f}')\n",
    "\n",
    "sess.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
