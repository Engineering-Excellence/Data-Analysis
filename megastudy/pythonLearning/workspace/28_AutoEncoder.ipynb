{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/homebrew/Caskroom/miniconda/base/envs/py_3_8/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 오토 인코더(Auto Encoder)\n",
    "오토인코더는 아주 간단하면서 강력한 비지도 학습 딥러닝 모델이다.\n",
    "입력값을 압축시킨 후, 다시 압축된 정보를 복원해서 입력값과 동일한 출력값을 가지도록 리턴하는 학습 모델이다.\n",
    "학습 과정을 통해 최대한 입력값과 출력값이 일치하도록 모델 파라미터가 최적화되고 오토인코더의 압축된 정보는 입력값에서 노이즈가 제거된 핵심 특징들로 구성된 저차원 데이터로 간주되어 주로 차원 축소의 목적으로 오토인코더가 많이 사용된다.\n",
    "<br/>\n",
    "<img src=\"./images/autoencoder.png\" width=\"1500\" />\n",
    "\n",
    "오토인코더는 크게 인코도와 디코더로 구분돼 있고, 인코더와 디코더 사이에는 압축된 정보가 존재한다.\n",
    "인코더와 디코더는 덴즈 레이어로 구성돼 있고, 인코더와 디코더 사이에는 입력 원본값보다 작은 차원을 갖는 덴즈 레이어를 두어 정보를 압축한다.\n",
    "\n",
    "MNIST 손글씨 데이터를 오토인코더를 사용해서 차원 축소 후 시각화한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "MNIST 손글씨 데이터를 획득한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "획득된 학습 데이터는 오토인코더 학습에 사용하고 테스트 데이터 중 500개의 데이터만 선택해서 시각화에 사용한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)  # 학습 데이터\n",
    "\n",
    "# 테스트 데이터 중 500개만 선택해서 테스트 데이터로 사용한다. => 데이터 시각화에 사용한다.\n",
    "x_test = x_test[:500]\n",
    "x_test = x_test.reshape(500, 784)  # 테스트 데이터\n",
    "y_test = y_test[:500]\n",
    "\n",
    "# 데이터 정규화\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "gray_scale = 255\n",
    "x_train /= gray_scale\n",
    "x_test /= gray_scale"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "텐서플로우 모델을 만든다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 텐서플로우 모델을 구현한다. 손실 함수는 입력값과 출력값의 차이를 최소화하는 것으로 설정한다.\n",
    "_input = tf.placeholder(dtype=tf.float32, shape=[None, 28 * 28])  # 입력\n",
    "encoder = tf.layers.dense(_input, 128, tf.nn.tanh)  # 인코더\n",
    "bottlenect = tf.layers.dense(encoder, 3)  # 3차원으로 차원축소\n",
    "decoder = tf.layers.dense(bottlenect, 128, tf.nn.tanh)  # 디코더\n",
    "_output = tf.layers.dense(decoder, 28 * 28, tf.nn.sigmoid)  # 출력\n",
    "loss = tf.losses.mean_squared_error(labels=_input, predictions=_output)  # 손실함수\n",
    "train = tf.train.AdamOptimizer(0.002).minimize(loss)  # 최적화"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "학습 데이터를 batch_size개씩 나눠서 데이터 학습을 진행한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n",
      "학습 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 12:35:29.331417: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-13 12:35:29.331677: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2023-03-13 12:35:29.339870: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n",
      "2023-03-13 12:35:29.346081: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-03-13 12:35:29.353806: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-13 12:35:29.399167: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, train loss: 0.174\n",
      "epoch:  1, train loss: 0.073\n",
      "epoch:  2, train loss: 0.068\n",
      "epoch:  3, train loss: 0.067\n",
      "epoch:  4, train loss: 0.066\n",
      "epoch:  5, train loss: 0.064\n",
      "epoch:  6, train loss: 0.060\n",
      "epoch:  7, train loss: 0.058\n",
      "epoch:  8, train loss: 0.058\n",
      "epoch:  9, train loss: 0.057\n",
      "epoch: 10, train loss: 0.056\n",
      "epoch: 11, train loss: 0.056\n",
      "epoch: 12, train loss: 0.055\n",
      "epoch: 13, train loss: 0.054\n",
      "epoch: 14, train loss: 0.054\n",
      "epoch: 15, train loss: 0.053\n",
      "epoch: 16, train loss: 0.053\n",
      "epoch: 17, train loss: 0.053\n",
      "epoch: 18, train loss: 0.052\n",
      "epoch: 19, train loss: 0.052\n",
      "epoch: 20, train loss: 0.051\n",
      "epoch: 21, train loss: 0.051\n",
      "epoch: 22, train loss: 0.051\n",
      "epoch: 23, train loss: 0.051\n",
      "epoch: 24, train loss: 0.050\n",
      "epoch: 25, train loss: 0.050\n",
      "epoch: 26, train loss: 0.050\n",
      "epoch: 27, train loss: 0.050\n",
      "epoch: 28, train loss: 0.049\n",
      "epoch: 29, train loss: 0.049\n",
      "epoch: 30, train loss: 0.049\n",
      "epoch: 31, train loss: 0.049\n",
      "epoch: 32, train loss: 0.048\n",
      "epoch: 33, train loss: 0.048\n",
      "epoch: 34, train loss: 0.048\n",
      "epoch: 35, train loss: 0.048\n",
      "epoch: 36, train loss: 0.047\n",
      "epoch: 37, train loss: 0.047\n",
      "epoch: 38, train loss: 0.047\n",
      "epoch: 39, train loss: 0.047\n",
      "epoch: 40, train loss: 0.047\n",
      "epoch: 41, train loss: 0.046\n",
      "epoch: 42, train loss: 0.046\n",
      "epoch: 43, train loss: 0.046\n",
      "epoch: 44, train loss: 0.046\n",
      "epoch: 45, train loss: 0.046\n",
      "epoch: 46, train loss: 0.046\n",
      "epoch: 47, train loss: 0.045\n",
      "epoch: 48, train loss: 0.045\n",
      "epoch: 49, train loss: 0.045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 12:35:37.619098: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(35)\n",
    "epoch_cnt = 50\n",
    "batch_size = 5000\n",
    "iteration = len(x_train) // batch_size\n",
    "# print(iteration)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('학습 시작...')\n",
    "    for epoch in range(epoch_cnt):\n",
    "        avg_loss = 0.0\n",
    "        start = 0\n",
    "        end = batch_size\n",
    "        for i in range(iteration):\n",
    "            _, loss_ = sess.run([train, loss], feed_dict={_input: x_train[start:end]})\n",
    "            start += batch_size\n",
    "            end += batch_size\n",
    "            # 손실 계산\n",
    "            avg_loss += loss_ / iteration\n",
    "        # ===== for i\n",
    "        print('epoch: {:2d}, train loss: {:5.3f}'.format(epoch, avg_loss))\n",
    "    # ===== 학습 종료\n",
    "    # 학습을 완료한 후 오토인코더의 3차원으로 압축된 벡터를 별도로 저장한다.\n",
    "    _bottlenect = sess.run(bottlenect, feed_dict={_input: x_test})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "압축된 데이터를 시각화 한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from pylab import rcParams"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x800 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rcParams['figure.figsize'] = [10, 8]\n",
    "fig = plt.figure(1)\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "xs = _bottlenect[:, 0]\n",
    "ys = _bottlenect[:, 1]\n",
    "zs = _bottlenect[:, 2]\n",
    "\n",
    "color = ['red', 'green', 'blue', 'lime', 'white', 'pink', 'aqua', 'violet', 'gold', 'coral']\n",
    "for x, y, z, label in zip(xs, ys, zs, y_test):\n",
    "    c = color[int(label)]\n",
    "    ax.text(x, y, z, label, backgroundcolor=c)\n",
    "\n",
    "ax.set_xlim(xs.min(), xs.max())\n",
    "ax.set_ylim(ys.min(), ys.max())\n",
    "ax.set_zlim(zs.min(), zs.max())\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "간단한 오토인코더임에도 784(28 * 28) 차원의 MNIST 데이터가 3차원으로 잘 축소되서 시각화했을 때 동일한 숫자를 의미하는 데이터포인트가 잘 군집된것을 확인할 수 있다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
